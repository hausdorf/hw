\documentclass[fleqn]{article}

\usepackage{mydefs}
\usepackage{notes}
\usepackage{url}
\usepackage{algorithm}
\usepackage{algorithmic}

\begin{document}
\lecture{CS 7960 }{Streaming Problem Set}{Alex Clemmer, u0458675}

% IF YOU ARE USING THIS .TEX FILE AS A TEMPLATE, PLEASE REPLACE
% "CS5350, Fall 2011" WITH YOUR NAME AND UID.

\section{Building $B$-Trees in External Memory	}

The key insight of the $B^{+}$-Tree is that it stores records (``satellite information") at the leaf level of the tree, which allows for a larger branching factor, which makes the height of the tree smaller, which allows for fewer IOs. So how many IOs does it take to construct such a tree from $O(N/B)$ contiguous blocks of memory?

\subsection{The algorithm}

The insertion case of $B$-Trees (\textit{i.e.}, the general case of $B$-Trees, not just the $B^+$-Tree specifically) is programmatically similar to the insertion case of BSTs, but with a few significant added complications. We still begin by looking for the leaf position to insert the key at, but actually inserting the key is restricted by the fact that the $B$-Tree must remain balanced.

This problem more or less breaks down into a couple basic cases. If the leaf block we're planning to insert to is $\textit{not}$ full, then we can simply add the record. If it actually is full, we want to run a $\texttt{split}$ procedure on the leaf.

$\texttt{split}$ is conceptually simple: we allocate a new leaf, and move half the records from the current leaf into the new leaf. We then want to take this new leaf's smallest key and insert it into the parent, in addition to the middle key. If the parent is full, we $\texttt{split}$ that too.

Notably, there is a way to do this in a single pass (as opposed to one pass both to find the leaf position, and $n$ more IOs to split all parents that need to be split), and while this will reduce our constants, it will not reduce the order of our IOs.

\subsection{Analysis}

There are $O(N/B)$ contiguous (unsorted) blocks of memory. Just reading this data will thus take $O(N/B)$ IOs at a minimum.

As noted above, an insertion (like most operations on $B$-Trees) is proportional to the height. Thus the asymptotic bound of IOs will depend on this factor.

The root contains at least 1 key and all the other nodes should contain at least $d - 1$ keys. Any $B$-Tree will then have at least 2 nodes at depth 1 (for obvious reasons we disallow the minimum degree $d = 1$), and 2$d$ at depth 2, and 2$d^2$ nodes at depth 3, until we come to the height $h$ of the tree, at which point the total will be 2$d^{h-1}$. Thus the height of the tree grows at $O(\mbox{log } n)$. Or, more precisely, for any $n$-key $B$-Tree where $n \ge 1$, we can say that for some minimum degree $d \ge 2$, the height $h \le log_d \frac{n+1}{2}$.

From this we can trivially see that it takes $O(h) = O(\log_B N)$ IOs to actually do an insertion. Over multiple insertions, however, we will be bounded to some extent by the number of such blocks we can fit in memory, which puts us squarely in $O(h) = O(\log_\frac{M}{B} \frac{N}{B})$. There are $O(N/B)$ IOs to read the elements, and each of these requires an insertion, so the total IOs is $O(\frac{N}{B} \log_\frac{M}{B} \frac{N}{B})$.


\section{Aggressive Approximate Counts}

\bee
\i When $k=1$, $S(x)$ will return either $a_m$ (the last element in the stream) or $m/k$ (the ``default" value). This is guaranteed by the $\texttt{else}$ condition: when we have only one counter-index pair, that pair is always $c_{\mbox{min}}$, and therefore we will always increment $c_i$ and set $t_i = a_j$. Any query that is not the last number in the stream will yield $m/k$.

\i When $k=2$, $c_1 + c_2 = m$. No matter what, we will always increment either $c_1$ or $c_2$. There is no way to avoid this. Thus, adding them gives us $m$.

\i If $k=2$ and $f_x > m/2$, then $S(x) > m/2$. We can trivially see that if the stream is split between 2 numbers, $p$ and $q$ such that $c_p > c_q$, then one of the counts $c_i$ will be at least 1 greater than the other. At this point, we could split up $c_q$ between any number of unique numbers. Unfortunately, there is no way to divide $c_q$ such that $c_p < c_q$. Since each of these numbers will have a smaller count than $q$, this property must hold no matter how the count is divided. Thus, $S(x) > m/2$ for any case where $f_x > m/2$.

\i These circumstances provide a maximum $|S(x_r) - f_{x_r}| = 0$. The reason is, if there are $k$ counter-index pairs and exactly $k$ numbers $\{x_1 \ldots x_k\}$ for which it is true that $f_{x_i} > 0$, then every $x_i$ will be tracked by one counter-index pair $(c_i, t_i)$, which means that $S(x)$ should always be precise.

\i In this case, at most, $c_i = m/k$. There are $k$ counter-index pairs, and we must pick the minimum. The smallest of these counters will at most be $m/k$ (or else the sum of counters will be $> m$).

\i In this case, the maximum is $|S(x) - f_x| = m/k$. Let's say there are $k + 1$ total elements in the stream, that the last two elements in the stream are equal, (\textit{i.e.}, $a_k = a_{k+1}$), and that their value is not found anywhere else in the stream. When we encounter $a_k$, we are forced by the \texttt{else} clause to increment $c_{min}$ and replace $t_{min} = a_k$. Then, when we encounter $a_{k+1}$, we increment this count again. From above we know that at most $c_{min} = m/k$, which makes $c_{a_{k+1}} = m/k + 2$. Since $f_{a_{k+1}} = 2$, at most $|S(x) - f_x| = m/k + 2 - 2 = m/k$.

\i No. Reassigning $t_i = x'$ to $t_i = x$ requires that the corresponding $c_i$ is actually one of the $c_{min}$'s. Reassignment also involves incrementing $c_i$, which makes this count bigger than current $f_{x'}$. Encountering $x'$ again will cause us to reassign to one of the pairs with count $c_{min}$; since $c_{x'}$ had to be a $c_{min}$ to be overwritten to begin with, the current pool of $c_{min}$'s is at least as large as $c_{x'}$ was. Thus there is no way to have processed more than $c_i$ instances of $x'$ than the variable indicates.

\i No. From the last section we know that some for some $t_i = x$, the count $c_i \ge f_{x_i}$.

\i No.

\ene


\section{Randomized Approximate Range Searching}

For any query interval, the goal of $S$ is for $P(|S(R) - \mbox{size}(R)| > \epsilon m) < \delta$. We're maintaining $k$ independent samples, which will determine exactly what our error rate is. We'll see how to control this in a minute.

Ensuring this bound is pretty straightforward:

\begin{algorithmic}
\FOR{$s_i \in R$ with probability $(size(R) / m)$} 
\STATE $Y_i \gets \{1 $ if $s_i \in R, 0 else\}$
\STATE $X_i \gets (Y_i - size(R) / m) / k$ if $s_i \in R, 0 else\}$
\ENDFOR
\end{algorithmic}

Notably, the error count estimate of $S$ is $M = \sum X_i$. The Chernoff bound is useful here:

\begin{eqnarray}
P(|M - \sum \mathbb{E}[X_i] | > \alpha) < 2 \cdot exp(-2 \alpha^2 / \sum_i (\Delta_i)^2) \\
P(|M| > \epsilon) < 2 \cdot exp(-2 \epsilon^2 / (k (1/k^2)))
\end{eqnarray}

Note here that usually $\mathbb{E}[X_i] = 0$. From here, we solve for $k$, yielding $k \in O(1/\epsilon^2 \log (1/\delta))$, which determines how many $k$ we'll need to control the error to the extent we wish.

\end{document}
